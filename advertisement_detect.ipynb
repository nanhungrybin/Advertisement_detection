{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 라벨링해서 광고 classification modeling 할 수 있도록"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# JSON 파일 읽기\n",
        "def load_json(json_path):\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "json_path = \"/home/azureuser/cloudfiles/code/Users/hb.suh/OUR_BERT/CODE/사출성형/Preprocessing_data/Blog/KOREAN/blog_naver_preprocessed.json\"\n",
        "\n",
        "json_data = load_json(json_path)\n",
        "# 데이터 프레임 생성\n",
        "df = pd.DataFrame(json_data)\n",
        "df['text'] = df['contents'].apply(lambda x: x['text'])\n",
        "df['label'] = df['advertisement'].apply(lambda x: 1 if x == \"TRUE\" else 0)\n",
        "\n",
        "# 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/llm-rag-embeddings/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1716187346045
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "# 토크나이저 로드\n",
        "tokenizer = BertTokenizer.from_pretrained(\"beomi/kcbert-base\")\n",
        "\n",
        "# 토크나이저 함수 정의\n",
        "def tokenize_data(texts, labels, tokenizer, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    #labels = torch.tensor(labels)\n",
        "    labels = torch.tensor(labels.values) \n",
        "\n",
        "    return input_ids, attention_masks, labels\n",
        "\n",
        "# 학습 및 테스트 데이터 토크나이징\n",
        "X_train_ids, X_train_masks, y_train_tensor = tokenize_data(X_train, y_train, tokenizer)\n",
        "X_test_ids, X_test_masks, y_test_tensor = tokenize_data(X_test, y_test, tokenizer)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716187691743
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로더 준비\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = TensorDataset(X_train_ids, X_train_masks, y_train_tensor)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_test_ids, X_test_masks, y_test_tensor)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716187692617
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구축 및 학습\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# BERT 모델 로드\n",
        "model = BertForSequenceClassification.from_pretrained(\"beomi/kcbert-base\", num_labels=2)\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# GPU 사용 설정 (가능한 경우)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/anaconda/envs/llm-rag-embeddings/lib/python3.8/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n      (position_embeddings): Embedding(300, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716187700388
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수 정의\n",
        "def train_model(model, train_dataloader, optimizer, device, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_dataloader:\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            b_input_ids = b_input_ids.to(device)\n",
        "            b_input_mask = b_input_mask.to(device)\n",
        "            b_labels = b_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_loss = total_loss / len(train_dataloader)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss}')\n",
        "\n",
        "# 모델 학습\n",
        "train_model(model, train_dataloader, optimizer, device)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10, Loss: 0.019439411039153736\nEpoch 2/10, Loss: 0.014116475358605385\nEpoch 3/10, Loss: 0.009192390056947866\nEpoch 4/10, Loss: 0.007614761435737212\nEpoch 5/10, Loss: 0.005610703645894925\nEpoch 6/10, Loss: 0.0050727858518560725\nEpoch 7/10, Loss: 0.004381177946925163\nEpoch 8/10, Loss: 0.003605213947594166\nEpoch 9/10, Loss: 0.0032880941095451512\nEpoch 10/10, Loss: 0.0029936484837283692\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716187750280
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 평가 함수 정의 (잘못 예측된 데이터 식별 포함)\n",
        "def evaluate_model(model, test_dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    misclassified_samples = []  # 잘못 예측된 데이터 저장\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            b_input_ids = b_input_ids.to(device)\n",
        "            b_input_mask = b_input_mask.to(device)\n",
        "            b_labels = b_labels.to(device)\n",
        "\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            logits = outputs.logits\n",
        "            _, predicted = torch.max(logits, dim=1)\n",
        "            \n",
        "            total += b_labels.size(0)\n",
        "            correct += (predicted == b_labels).sum().item()\n",
        "            \n",
        "            all_labels.extend(b_labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            \n",
        "            # 잘못 예측된 데이터 식별\n",
        "            for i in range(len(b_labels)):\n",
        "                if predicted[i] != b_labels[i]:\n",
        "                    misclassified_samples.append({\n",
        "                        'input_ids': b_input_ids[i].cpu().numpy(),\n",
        "                        'attention_mask': b_input_mask[i].cpu().numpy(),\n",
        "                        'label': b_labels[i].item(),\n",
        "                        'prediction': predicted[i].item()\n",
        "                    })\n",
        "\n",
        "    accuracy = correct / total\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average=None)\n",
        "    \n",
        "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "    print(f'Precision: {precision}')\n",
        "    print(f'Recall: {recall}')\n",
        "    print(f'F1-score: {f1}')\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.show()\n",
        "    \n",
        "    # 잘못 예측된 데이터 출력\n",
        "    print(\"\\nMisclassified Samples:\")\n",
        "    for sample in misclassified_samples:\n",
        "        input_text = tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
        "        print(f\"Text: {input_text}\")\n",
        "        print(f\"Actual Label: {sample['label']}, Predicted Label: {sample['prediction']}\\n\")\n",
        "\n",
        "# 모델 평가\n",
        "evaluate_model(model, test_dataloader, device)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy: 84.62%\nPrecision: [0.85714286 0.83333333]\nRecall: [0.85714286 0.83333333]\nF1-score: [0.85714286 0.83333333]\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nMisclassified Samples:\nText: 우진플라임의 전동식 사출성형기 사출부 TE - G5 고강성 인라인 사출장치 사출하우징과 사출 볼스크류부 장치 부분을 하나의 부품 ( 주물 ) 으로 구성됩니다. 사출 베드 및 계량부 LM 가이드 적용합니다. 2. 스크류 피치와 길이 ( L / D : 20 / 1 에서 22 / 1 ) 향상된 가소화능력으로 빠르고 균일한 수지응용 및 쿠션 편차 비율 감소합니다. 3. 듀얼 풀 노즐터치 실린더 반복적인.\nActual Label: 0, Predicted Label: 1\n\nText: 추출은 자동화된 기계나 작업자가 하며 제품이 사출기에서 제거된 후, 추가적인 작업이 필요한 경우도 있습니다 ~! 오늘 소개해 드릴 제품은 160 / 170톤의 사출 성형기로 400g 이하의 제품을 생산할 수 있습니다. 고온과 냉각이 반복되며 지속적인 작업을 수행할 경우, 어떤 기계는 발열이 심해져 자칫하면 화재가 발생할 수 있는 위험성이 있습니다. 하지만 이 플라스틱.\nActual Label: 1, Predicted Label: 0\n\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716188747550
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예측 TESTING"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "def predict_advertisement(model, tokenizer, text, device, max_length=256):\n",
        "    model.eval()\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "    \n",
        "    input_ids = encoded_dict['input_ids'].to(device)\n",
        "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        _, predicted = torch.max(logits, dim=1)\n",
        "        \n",
        "    return 'TRUE' if predicted.item() == 1 else 'FALSE'\n",
        "\n",
        "# 새 JSON 데이터\n",
        "new_data = {\n",
        "    \"ID\": 59,\n",
        "    \"advertisement\": \"TRUE\",\n",
        "    \"contents\": {\n",
        "        \"title\": \"나주공장경매 나주시 왕곡면 덕산리 공장용지2426평 최저가48억 플라스틱\",\n",
        "        \"text\": \"오늘 소개하는 전라남도 나주시 왕곡면 덕산리에 소재하는 공장은 포장용 플라스틱 성형용기 제조, 금형플라스틱사출성형, 프레스가공 공장은 나주공장경매 나주시 왕곡면 덕산리 공장용지2426평 일반공업지역 최저가48억 플라스틱 제조공장에 대한 자세한 내용은 부동산전문 법률사무소 담당자에게 문의주시면 친절하게.\"\n",
        "    },\n",
        "    \"link\": \"https://goodauction.tistory.com/413\",\n",
        "    \"source\": \"naver_blog\",\n",
        "    \"date\": \"2024-04-02 16:16:58\",\n",
        "    \"language\": \"korean\"\n",
        "}\n",
        "\n",
        "# 예측 실행\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "tokenizer = BertTokenizer.from_pretrained('beomi/kcbert-base')\n",
        "text = new_data['contents']['text']\n",
        "prediction = predict_advertisement(model, tokenizer, text, device)\n",
        "print(f'Predicted advertisement: {prediction}')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Predicted advertisement: TRUE\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/llm-rag-embeddings/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716188233651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "llm-rag-embeddings",
      "language": "python",
      "display_name": "genai"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "llm-rag-embeddings"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}